{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: category-encoders in c:\\users\\abdel\\ideaprojects\\goyave-back\\venv\\lib\\site-packages (2.6.3)\n",
      "Requirement already satisfied: pandas>=1.0.5 in c:\\users\\abdel\\ideaprojects\\goyave-back\\venv\\lib\\site-packages (from category-encoders) (2.1.3)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\users\\abdel\\ideaprojects\\goyave-back\\venv\\lib\\site-packages (from category-encoders) (1.11.4)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in c:\\users\\abdel\\ideaprojects\\goyave-back\\venv\\lib\\site-packages (from category-encoders) (0.14.0)\n",
      "Requirement already satisfied: patsy>=0.5.1 in c:\\users\\abdel\\ideaprojects\\goyave-back\\venv\\lib\\site-packages (from category-encoders) (0.5.3)\n",
      "Requirement already satisfied: numpy>=1.14.0 in c:\\users\\abdel\\ideaprojects\\goyave-back\\venv\\lib\\site-packages (from category-encoders) (1.26.0)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\abdel\\ideaprojects\\goyave-back\\venv\\lib\\site-packages (from category-encoders) (1.3.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\abdel\\ideaprojects\\goyave-back\\venv\\lib\\site-packages (from pandas>=1.0.5->category-encoders) (2023.3.post1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\abdel\\ideaprojects\\goyave-back\\venv\\lib\\site-packages (from pandas>=1.0.5->category-encoders) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\abdel\\ideaprojects\\goyave-back\\venv\\lib\\site-packages (from pandas>=1.0.5->category-encoders) (2023.3)\n",
      "Requirement already satisfied: six in c:\\users\\abdel\\ideaprojects\\goyave-back\\venv\\lib\\site-packages (from patsy>=0.5.1->category-encoders) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\abdel\\ideaprojects\\goyave-back\\venv\\lib\\site-packages (from scikit-learn>=0.20.0->category-encoders) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\abdel\\ideaprojects\\goyave-back\\venv\\lib\\site-packages (from scikit-learn>=0.20.0->category-encoders) (3.2.0)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\abdel\\ideaprojects\\goyave-back\\venv\\lib\\site-packages (from statsmodels>=0.9.0->category-encoders) (23.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "!pip install category-encoders\n",
    "from category_encoders import OrdinalEncoder\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Dates        Category  DayOfWeek           X          Y\n",
      "0  2015-05-13 23:53:00        WARRANTS  Wednesday -122.425892  37.774599\n",
      "1  2015-05-13 23:53:00  OTHER OFFENSES  Wednesday -122.425892  37.774599\n",
      "2  2015-05-13 23:33:00  OTHER OFFENSES  Wednesday -122.424363  37.800414\n",
      "3  2015-05-13 23:30:00   LARCENY/THEFT  Wednesday -122.426995  37.800873\n",
      "4  2015-05-13 23:30:00   LARCENY/THEFT  Wednesday -122.438738  37.771541\n",
      "['WARRANTS' 'OTHER OFFENSES' 'LARCENY/THEFT' 'VEHICLE THEFT' 'VANDALISM'\n",
      " 'NON-CRIMINAL' 'ROBBERY' 'ASSAULT' 'WEAPON LAWS' 'BURGLARY'\n",
      " 'SUSPICIOUS OCC' 'DRUNKENNESS' 'FORGERY/COUNTERFEITING' 'DRUG/NARCOTIC'\n",
      " 'STOLEN PROPERTY' 'SECONDARY CODES' 'TRESPASS' 'MISSING PERSON' 'FRAUD'\n",
      " 'KIDNAPPING' 'RUNAWAY' 'DRIVING UNDER THE INFLUENCE'\n",
      " 'SEX OFFENSES FORCIBLE' 'PROSTITUTION' 'DISORDERLY CONDUCT' 'ARSON'\n",
      " 'FAMILY OFFENSES' 'LIQUOR LAWS' 'BRIBERY' 'EMBEZZLEMENT' 'SUICIDE'\n",
      " 'LOITERING' 'SEX OFFENSES NON FORCIBLE' 'EXTORTION' 'GAMBLING'\n",
      " 'BAD CHECKS' 'TREA' 'RECOVERED VEHICLE' 'PORNOGRAPHY/OBSCENE MAT']\n",
      "{'ASSAULT': 'Crimes against the person', 'ROBBERY': 'Crimes against the person', 'KIDNAPPING': 'Crimes against the person', 'SEX OFFENSES FORCIBLE': 'Crimes against the person', 'SEX OFFENSES NON FORCIBLE': 'Crimes against the person', 'HOMICIDE': 'Crimes against the person', 'LARCENY/THEFT': 'Crimes against property', 'VEHICLE THEFT': 'Crimes against property', 'BURGLARY': 'Crimes against property', 'VANDALISM': 'Crimes against property', 'STOLEN PROPERTY': 'Crimes against property', 'RECOVERED VEHICLE': 'Crimes against property', 'ARSON': 'Crimes against property', 'FRAUD': 'Crimes against property', 'EMBEZZLEMENT': 'Crimes against property', 'EXTORTION': 'Crimes against property', 'BRIBERY': 'Crimes against property', 'FORGERY/COUNTERFEITING': 'Crimes against property', 'BAD CHECKS': 'Crimes against property', 'DRUNKENNESS': 'Crimes related to alcohol and drugs', 'DRUG/NARCOTIC': 'Crimes related to alcohol and drugs', 'LIQUOR LAWS': 'Crimes related to alcohol and drugs', 'DRIVING UNDER THE INFLUENCE': 'Crimes related to alcohol and drugs', 'DISORDERLY CONDUCT': 'Crimes related to public order', 'TRESPASS': 'Crimes related to public order', 'LOITERING': 'Crimes related to public order', 'SUSPICIOUS OCC': 'Crimes related to public order', 'FAMILY OFFENSES': 'Crimes related to public order', 'WARRANTS': 'Miscellaneous', 'OTHER OFFENSES': 'Miscellaneous', 'NON-CRIMINAL': 'Miscellaneous', 'SECONDARY CODES': 'Miscellaneous', 'MISSING PERSON': 'Miscellaneous', 'RUNAWAY': 'Miscellaneous', 'GAMBLING': 'Miscellaneous', 'PORNOGRAPHY/OBSCENE MAT': 'Miscellaneous', 'TREA': 'Miscellaneous'}\n",
      "Category     0\n",
      "DayOfWeek    0\n",
      "X            0\n",
      "Y            0\n",
      "Year         0\n",
      "Month        0\n",
      "Day          0\n",
      "Hour         0\n",
      "Minute       0\n",
      "Second       0\n",
      "dtype: int64\n",
      "Category     False\n",
      "DayOfWeek    False\n",
      "X            False\n",
      "Y            False\n",
      "Year         False\n",
      "Month        False\n",
      "Day          False\n",
      "Hour         False\n",
      "Minute       False\n",
      "Second       False\n",
      "dtype: bool\n",
      "Category     0\n",
      "DayOfWeek    0\n",
      "X            0\n",
      "Y            0\n",
      "Year         0\n",
      "Month        0\n",
      "Day          0\n",
      "Hour         0\n",
      "Minute       0\n",
      "Second       0\n",
      "dtype: int64\n",
      "        Category  DayOfWeek           X          Y  Year  Month  Day  Hour  \\\n",
      "0              1          1 -122.441056  37.725889  2006     10   19    14   \n",
      "1              1          2 -122.463133  37.742622  2009      8    3    23   \n",
      "2              1          3 -122.502874  37.746509  2003      7    9    20   \n",
      "3              1          4 -122.391981  37.728037  2003     12   13     0   \n",
      "4              1          5 -122.449116  37.777322  2013      3    5    18   \n",
      "...          ...        ...         ...        ...   ...    ...  ...   ...   \n",
      "223850         5          7 -122.483556  37.785869  2014      3   21     5   \n",
      "223851         5          4 -122.490923  37.761085  2006     11    4     1   \n",
      "223852         5          2 -122.447539  37.778615  2007      8    6    16   \n",
      "223853         5          4 -122.424413  37.768005  2005      7   30    18   \n",
      "223854         5          1 -122.412999  37.786277  2013      1   24    19   \n",
      "\n",
      "        Minute  Second  \n",
      "0            0       0  \n",
      "1            0       0  \n",
      "2            0       0  \n",
      "3            6       0  \n",
      "4            0       0  \n",
      "...        ...     ...  \n",
      "223850      19       0  \n",
      "223851      23       0  \n",
      "223852       0       0  \n",
      "223853      49       0  \n",
      "223854      14       0  \n",
      "\n",
      "[223855 rows x 10 columns]\n",
      "(223855, 10)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('./data/sf-crime/train.csv')\n",
    "\n",
    "columns_deleted = ['Descript','Resolution','Address', 'PdDistrict']\n",
    "data = data.drop(columns_deleted, axis=1)\n",
    "print(data.head())\n",
    "\n",
    "# Les valeurs connues pour la suppression\n",
    "# category_a_supprimer = 'WARRANTS'\n",
    "x_a_supprimer = -120.5\n",
    "y_a_supprimer = 90\n",
    "\n",
    "# Supprimer les lignes où les valeurs correspondent aux valeurs connues\n",
    "# data = data[~((data['Category'] == category_a_supprimer) & (data['X'] == x_a_supprimer) & (data['Y'] == y_a_supprimer))]\n",
    "data = data[~((data['X'] == x_a_supprimer) & (data['Y'] == y_a_supprimer))]\n",
    "\n",
    "categories_uniques = data['Category'].unique()\n",
    "print(categories_uniques)\n",
    "# Définir les catégories\n",
    "categories = {\n",
    "    \"Crimes against the person\": [\n",
    "        'ASSAULT', 'ROBBERY', 'KIDNAPPING', 'SEX OFFENSES FORCIBLE',\n",
    "        'SEX OFFENSES NON FORCIBLE', 'HOMICIDE'\n",
    "    ],\n",
    "    \"Crimes against property\": [\n",
    "        'LARCENY/THEFT', 'VEHICLE THEFT', 'BURGLARY', 'VANDALISM',\n",
    "        'STOLEN PROPERTY', 'RECOVERED VEHICLE', 'ARSON', 'FRAUD',\n",
    "        'EMBEZZLEMENT', 'EXTORTION', 'BRIBERY', 'FORGERY/COUNTERFEITING',\n",
    "        'BAD CHECKS'\n",
    "    ],\n",
    "    \"Crimes related to alcohol and drugs\": [\n",
    "        'DRUNKENNESS', 'DRUG/NARCOTIC', 'LIQUOR LAWS','DRIVING UNDER THE INFLUENCE'\n",
    "    ],\n",
    "    \"Crimes related to public order\": [\n",
    "        'DISORDERLY CONDUCT', 'TRESPASS', 'LOITERING', 'SUSPICIOUS OCC','FAMILY OFFENSES'\n",
    "    ],\n",
    "    \"Miscellaneous\": [\n",
    "        'WARRANTS', 'OTHER OFFENSES', 'NON-CRIMINAL', 'SECONDARY CODES',\n",
    "        'MISSING PERSON', 'RUNAWAY', 'GAMBLING', 'PORNOGRAPHY/OBSCENE MAT',\n",
    "        'TREA'\n",
    "    ]\n",
    "}\n",
    "# Créer un dictionnaire inversé pour obtenir les catégories pour chaque thème\n",
    "theme_categories = {}\n",
    "for category, themes_list in categories.items():\n",
    "    for theme in themes_list:\n",
    "        theme_categories[theme] = category\n",
    "\n",
    "print(theme_categories)\n",
    "\n",
    "# Utiliser le dictionnaire 'theme_categories' pour mapper chaque donnée à sa catégorie\n",
    "data['Category'] = data['Category'].map(theme_categories)\n",
    "\n",
    "# Randomiser les données\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# # Compter le nombre de données pour chaque catégorie\n",
    "counts_per_category = data['Category'].value_counts()\n",
    "#\n",
    "# # Trouver la taille de la catégorie la plus petite\n",
    "min_count = counts_per_category.min()\n",
    "#\n",
    "# # Sélectionner un nombre équilibré de données pour chaque catégorie (basé sur la taille de la catégorie la plus petite)\n",
    "balanced_data = pd.DataFrame()\n",
    "#\n",
    "for category, count in counts_per_category.items():\n",
    "    category_data = data[data['Category'] == category].sample(min(count, min_count))\n",
    "    balanced_data = pd.concat([balanced_data, category_data])\n",
    "#\n",
    "# # Enregistrer ce nouvel ensemble de données équilibré dans un fichier CSV\n",
    "balanced_data.to_csv('./data/sf-crime//balanced_dataset.csv', index=False)\n",
    "#\n",
    "data = pd.read_csv('./data/sf-crime/balanced_dataset.csv')\n",
    "\n",
    "# Mapper les catégories à partir des valeurs existantes de la colonne 'Category'\n",
    "data['Category'] = data['Category'].map(theme_categories).fillna(data['Category'])\n",
    "# Convertir la colonne 'Dates' en format datetime\n",
    "data['Dates'] = pd.to_datetime(data['Dates'])\n",
    "# Créer de nouvelles colonnes pour la date et l'heure\n",
    "data['Date'] = data['Dates'].dt.date\n",
    "data['Time'] = data['Dates'].dt.time\n",
    "# Supprimer la colonne 'Dates' maintenant qu'elle n'est plus nécessaire\n",
    "data.drop(columns=['Dates'], inplace=True)\n",
    "# Convertir la colonne 'Date' en composantes de date séparées\n",
    "data['Year'] = pd.to_datetime(data['Date']).dt.year\n",
    "data['Month'] = pd.to_datetime(data['Date']).dt.month\n",
    "data['Day'] = pd.to_datetime(data['Date']).dt.day\n",
    "# Convertir la colonne 'Time' en composantes d'heure séparées\n",
    "data['Hour'] = pd.to_datetime(data['Time'], format='%H:%M:%S').dt.hour\n",
    "data['Minute'] = pd.to_datetime(data['Time'], format='%H:%M:%S').dt.minute\n",
    "data['Second'] = pd.to_datetime(data['Time'], format='%H:%M:%S').dt.second\n",
    "# Supprimer les colonnes d'origine 'Date' et 'Time'\n",
    "data.drop(['Date', 'Time'], axis=1, inplace=True)\n",
    "# Colonnes à encoder de façon ordinaire\n",
    "ordinal_cols = ['Category', 'DayOfWeek']\n",
    "\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Créer un encodeur ordinal et appliquer la transformation\n",
    "encoder = OrdinalEncoder(cols=ordinal_cols).fit(data)\n",
    "data = encoder.transform(data)\n",
    "# Enregistrer le nouveau fichier CSV sans modifier l'original\n",
    "data.to_csv('./data/sf-crime/nouveau_fichier.csv', index=False)\n",
    "# Filtrer les données pour inclure uniquement la catégorie 'Harassment'\n",
    "larceny_theft_data = data[data['Category'] == 'Harassment']\n",
    "# Créer un nuage de points avec la catégorie 'PROSTITUTION'\n",
    "# fig = px.scatter(larceny_theft_data, x=\"X\", y=\"Y\", color=\"Category\")\n",
    "# fig.show()\n",
    "# Vérifier s'il y a des valeurs manquantes (NaN) dans chaque colonne\n",
    "missing_values = data.isnull().any()\n",
    "data.isnull().sum()\n",
    "# Afficher les colonnes contenant des valeurs manquantes (True) et le nombre de valeurs manquantes dans chaque colonne\n",
    "print(missing_values)\n",
    "print(data.isnull().sum())\n",
    "print(data)\n",
    "print(data.shape)\n",
    "\n",
    "#"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores de validation croisée : [0.35739653 0.35563199 0.36483438 0.36009917 0.36166268]\n",
      "Moyenne des scores : 0.35992495141944564\n",
      "Accuracy : 0.35844364697648795\n",
      "Confusion Matrix :\n",
      " [[5155 2420 2282 1100 2399]\n",
      " [2598 3299 2364 2575 2434]\n",
      " [2623 2453 4024 1972 2439]\n",
      " [1181 1783 1557 7679 1296]\n",
      " [2848 2561 2541 1659 3915]]\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.36      0.39      0.37     13356\n",
      "           2       0.26      0.25      0.26     13270\n",
      "           3       0.32      0.30      0.31     13511\n",
      "           4       0.51      0.57      0.54     13496\n",
      "           5       0.31      0.29      0.30     13524\n",
      "\n",
      "    accuracy                           0.36     67157\n",
      "   macro avg       0.35      0.36      0.35     67157\n",
      "weighted avg       0.35      0.36      0.36     67157\n",
      "\n",
      "Prédiction de la catégorie 1 la plus probable : 20.00%\n",
      "Prédiction de la catégorie 2 la plus probable : 20.00%\n",
      "Prédiction de la catégorie 3 la plus probable : 26.67%\n",
      "Prédiction de la catégorie 4 la plus probable : 0.00%\n",
      "Prédiction de la catégorie 5 la plus probable : 33.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdel\\IdeaProjects\\goyave-back\\venv\\lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "####### Model 1 #######\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Sélection des colonnes souhaitées pour les entrées du modèle\n",
    "selected_columns = ['DayOfWeek', 'X', 'Y', 'Hour']\n",
    "X = data[selected_columns]\n",
    "y = data['Category']\n",
    "#\n",
    "# # Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "#\n",
    "# # Create a RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=15, random_state=42,max_depth=20)\n",
    "\n",
    "# Entraînement du modèle\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Validation croisée (cross-validation)\n",
    "scores = cross_val_score(clf, X, y, cv=5)  # Utilisation de 5 folds pour la validation croisée\n",
    "\n",
    "# Affichage des scores de validation croisée\n",
    "print(\"Scores de validation croisée :\", scores)\n",
    "print(\"Moyenne des scores :\", scores.mean())\n",
    "\n",
    "# Prédictions sur l'ensemble de test\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "# Évaluation du modèle sur l'ensemble de test\n",
    "print(\"Accuracy :\", clf.score(X_test, y_test))\n",
    "print(\"Confusion Matrix :\\n\", confusion_matrix(y_test, predictions))\n",
    "print(\"Classification Report :\\n\", classification_report(y_test, predictions))\n",
    "\n",
    "# Nouvelles données à prédire\n",
    "new_data = [\n",
    "    [4, 37.7749, -122.4194, 8],\n",
    "    [2, 37.7996, -122.4000, 4]\n",
    "]\n",
    "\n",
    "# Obtention des probabilités des prédictions pour les nouvelles données\n",
    "predicted_probabilities = clf.predict_proba(new_data)[0]\n",
    "\n",
    "categories_uniques = data['Category'].unique()\n",
    "\n",
    "# Affichage des probabilités de chaque catégorie\n",
    "for i, category in enumerate(categories_uniques):\n",
    "    print(f\"Prédiction de la catégorie {category} la plus probable : {predicted_probabilities[i] * 100:.2f}%\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "####### Sauvegarde du Model 1 #######\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Sauvegarde du modèle dans un fichier\n",
    "with open('crime_prediction_model.pkl', 'wb') as file:\n",
    "    pickle.dump(clf, file)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
